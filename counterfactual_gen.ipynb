{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    BertForMaskedLM, GPT2LMHeadModel, GPT2TokenizerFast\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/ssd_scratch/sweta.jena\"\n",
    "dataset_name=\"imdb\"\n",
    "class_names = [\"negative\", \"positive\"]\n",
    "# sim_threshold=0.85\n",
    "# ppl_threshold=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment clf\n",
    "clf_name = \"textattack/bert-base-uncased-imdb\"   \n",
    "clf_tokenizer = AutoTokenizer.from_pretrained(clf_name, cache_dir = cache_dir)\n",
    "clf_model = AutoModelForSequenceClassification.from_pretrained(clf_name, cache_dir=cache_dir)\n",
    "clf_model.eval()\n",
    "\n",
    "# masked LM\n",
    "mlm_name = \"bert-base-uncased\"                   \n",
    "mlm_tokenizer = AutoTokenizer.from_pretrained(mlm_name, cache_dir = cache_dir)\n",
    "mlm_model = BertForMaskedLM.from_pretrained(mlm_name, cache_dir=cache_dir)\n",
    "mlm_model.eval()\n",
    "\n",
    "\n",
    "# fluency\n",
    "gpt2_name = \"gpt2\"                               \n",
    "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(gpt2_name, cache_dir = cache_dir)\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_name, cache_dir=cache_dir)\n",
    "gpt2_model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    clf_model = torch.nn.DataParallel(clf_model)\n",
    "    mlm_model = torch.nn.DataParallel(mlm_model)\n",
    "    gpt2_model = torch.nn.DataParallel(gpt2_model)\n",
    "clf_model.to(device)\n",
    "mlm_model.to(device)\n",
    "gpt2_model.to(device)\n",
    "\n",
    "#semantic sim\n",
    "sbert = SentenceTransformer(\"all-MiniLM-L6-v2\", device=str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c63313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(texts, batch_size=64):\n",
    "    \n",
    "    processed_texts = []\n",
    "    for t in texts:\n",
    "        if isinstance(t, (list, np.ndarray)):\n",
    "            processed_texts.append(clf_tokenizer.decode(t, skip_special_tokens=True))\n",
    "        else:\n",
    "            processed_texts.append(str(t))\n",
    "\n",
    "    all_probs = []\n",
    "    for i in range(0, len(processed_texts), batch_size):\n",
    "        batch = processed_texts[i:i+batch_size]\n",
    "        encodings = clf_tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = clf_model(**encodings)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "    return np.array(all_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candidates(text, word, top_k=10):\n",
    "    tokens = mlm_tokenizer.tokenize(text, max_length=512, truncation=True)\n",
    "    if word not in tokens:\n",
    "        return []\n",
    "\n",
    "    idx = tokens.index(word)\n",
    "    tokens[idx] = mlm_tokenizer.mask_token\n",
    "    masked_text = mlm_tokenizer.convert_tokens_to_string(tokens)\n",
    "    inputs = mlm_tokenizer(masked_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = mlm_model(**inputs).logits\n",
    "    mask_index = torch.where(inputs[\"input_ids\"][0] == mlm_tokenizer.mask_token_id)[0].item()\n",
    "    probs = torch.softmax(logits[0, mask_index], dim=0)\n",
    "    top_tokens = torch.topk(probs, top_k).indices.tolist()\n",
    "    candidates = [mlm_tokenizer.decode([t]) for t in top_tokens]\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf17af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity(text1, text2):\n",
    "    emb1 = sbert.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = sbert.encode(text2, convert_to_tensor=True)\n",
    "    return float(util.cos_sim(emb1, emb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71548506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(text):\n",
    "\n",
    "    model_config = gpt2_model.module.config if hasattr(gpt2_model, \"module\") else gpt2_model.config\n",
    "    max_length = model_config.n_positions\n",
    "    encodings = gpt2_tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length).to(device)\n",
    "    stride = 512\n",
    "\n",
    "    lls = []\n",
    "    for i in range(0, encodings.input_ids.size(1), stride):\n",
    "        begin_loc = max(i + stride - max_length, 0)\n",
    "        end_loc = min(i + stride, encodings.input_ids.size(1))\n",
    "        trg_len = end_loc - i\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc]\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "        with torch.no_grad():\n",
    "            outputs = gpt2_model(input_ids, labels=target_ids)\n",
    "            log_likelihood = outputs.loss * trg_len\n",
    "        lls.append(log_likelihood)\n",
    "    ppl = torch.exp(torch.stack(lls).sum() / end_loc)\n",
    "    return float(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ef6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(a, b):\n",
    "    return 1 - SequenceMatcher(None, a.split(), b.split()).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e69ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_counterfactual_with_lime(\n",
    "#     text, num_samples=1000, top_k_tokens=5\n",
    "# ):\n",
    "#     explainer = LimeTextExplainer(class_names=class_names)\n",
    "#     exp = explainer.explain_instance(\n",
    "#         text, predict_proba, num_features=5, labels=[0, 1], num_samples=num_samples\n",
    "#     )\n",
    "\n",
    "#     pred_label = np.argmax(predict_proba([text])[0])\n",
    "#     influential_tokens = [w for w, score in exp.as_list(label=pred_label)]\n",
    "#     if not influential_tokens:\n",
    "#         return None\n",
    "\n",
    "#     for target_word in influential_tokens[:top_k_tokens]:\n",
    "#         candidates = generate_candidates(text, target_word)\n",
    "#         for cand in candidates:\n",
    "#             new_text = text.replace(target_word, cand)\n",
    "#             new_pred = np.argmax(predict_proba([new_text])[0])\n",
    "#             if new_pred != pred_label:\n",
    "#                 sim = semantic_similarity(text, new_text)\n",
    "#                 flu = perplexity(new_text)\n",
    "#                 if sim >= sim_threshold and flu <= ppl_threshold:\n",
    "#                     return {\n",
    "#                         \"original_text\": text,\n",
    "#                         \"original_pred\": pred_label,\n",
    "#                         \"counterfactual_text\": new_text,\n",
    "#                         \"counterfactual_pred\": new_pred,\n",
    "#                         \"changed_word\": (target_word, cand),\n",
    "#                         \"semantic_similarity\": sim,\n",
    "#                         \"perplexity\": flu\n",
    "#                     }\n",
    "#     return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def truncate_texts(texts, max_len=512):\n",
    "#     if isinstance(texts, str):\n",
    "#         texts = [texts]\n",
    "\n",
    "#     enc = clf_tokenizer(\n",
    "#         texts,\n",
    "#         truncation=True,\n",
    "#         padding=False,\n",
    "#         max_length=max_len,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     truncated_texts = [\n",
    "#         clf_tokenizer.decode(ids, skip_special_tokens=True)\n",
    "#         for ids in enc[\"input_ids\"]\n",
    "#     ]\n",
    "#     return truncated_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d933a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_counterfactuals_with_shap_batch(texts, max_evals=1000):\n",
    "#     masker = shap.maskers.Text(tokenizer=clf_tokenizer)\n",
    "#     model_config = clf_model.module.config if hasattr(clf_model, \"module\") else clf_model.config\n",
    "#     labels = [model_config.id2label[i] for i in range(len(model_config.id2label))]\n",
    "\n",
    "#     explainer = shap.Explainer(predict_proba, masker, output_names=labels)\n",
    "#     shap_values = explainer(texts, max_evals=max_evals)   #batched call\n",
    "\n",
    "#     results = []\n",
    "#     for i, text in enumerate(texts):\n",
    "#         pred_label = np.argmax(predict_proba([text])[0])\n",
    "#         token_importances = shap_values.values[i, :, pred_label]\n",
    "#         tokens = shap_values.data[i]\n",
    "#         influential_tokens = [t for t, score in zip(tokens, token_importances) if score > 0]\n",
    "\n",
    "#         candidates = generate_candidates(text, influential_tokens)\n",
    "#         cf = None\n",
    "#         for cand, orig_token, repl_token in candidates:\n",
    "#             new_pred = np.argmax(predict_proba([cand])[0])\n",
    "#             if new_pred != pred_label:\n",
    "#                 sim = semantic_similarity(text, cand)\n",
    "#                 ppl = perplexity(cand)\n",
    "#                 cf = {\n",
    "#                     \"counterfactual_text\": cand,\n",
    "#                     \"changed_word\": (orig_token, repl_token),\n",
    "#                     \"semantic_similarity\": sim,\n",
    "#                     \"perplexity\": ppl\n",
    "#                 }\n",
    "#                 break\n",
    "#         results.append(cf)\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_counterfactual(cf, orig_text, method, sim_threshold=0.75, ppl_threshold=200):\n",
    "    if cf is None:\n",
    "        return {\n",
    "            \"success\": -1,\n",
    "            \"method\": method,\n",
    "            \"original_text\": orig_text,\n",
    "            \"counterfactual_text\": None,\n",
    "            \"changed_word\": None,\n",
    "            \"semantic_similarity\": None,\n",
    "            \"perplexity\": None,\n",
    "            \"edit_distance\": None,\n",
    "            \"original_embedding\": None,\n",
    "            \"counterfactual_embedding\": None,\n",
    "            \"mced\": None\n",
    "        }\n",
    "\n",
    "    orig_emb = sbert.encode(orig_text, convert_to_tensor=False)\n",
    "    cf_emb = sbert.encode(cf.get(\"counterfactual_text\"), convert_to_tensor=False)\n",
    "    ed = edit_distance(orig_text, cf.get(\"counterfactual_text\"))\n",
    "    mced = ed / max(1, len(orig_text.split()))  # normalized edit distance\n",
    "\n",
    "    if (cf.get(\"semantic_similarity\") >= sim_threshold) and (cf.get(\"perplexity\") <= ppl_threshold):\n",
    "        success = 1\n",
    "    else:\n",
    "        success = 0\n",
    "\n",
    "    return {\n",
    "        \"success\": success,\n",
    "        \"method\": method,\n",
    "        \"original_text\": cf.get(\"original_text\", orig_text),\n",
    "        \"counterfactual_text\": cf.get(\"counterfactual_text\"),\n",
    "        \"changed_word\": cf.get(\"changed_word\"),\n",
    "        \"semantic_similarity\": cf.get(\"semantic_similarity\"),\n",
    "        \"perplexity\": cf.get(\"perplexity\"),\n",
    "        \"edit_distance\": ed,\n",
    "        \"original_embedding\": orig_emb.tolist(),       \n",
    "        \"counterfactual_embedding\": cf_emb.tolist(),\n",
    "        \"mced\": mced\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_evaluate(\n",
    "    sample_size=-1,\n",
    "    dataset_name=\"imdb\",\n",
    "    batch_size=64,\n",
    "    max_len=512,\n",
    "    lime_num_samples=500,\n",
    "    shap_max_evals=500\n",
    "):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    test_data = dataset[\"test\"]\n",
    "\n",
    "    if sample_size == -1:\n",
    "        sample_size = len(test_data)\n",
    "        examples=list(test_data)\n",
    "        \n",
    "    else:\n",
    "        examples = random.sample(list(test_data), sample_size)\n",
    "\n",
    "    print(\"Sample size:\", sample_size)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    masker = shap.maskers.Text(tokenizer=clf_tokenizer)\n",
    "    model_config = clf_model.module.config if hasattr(clf_model, \"module\") else clf_model.config\n",
    "    labels = [model_config.id2label[i] for i in range(len(model_config.id2label))]\n",
    "    shap_explainer = shap.Explainer(predict_proba, masker, output_names=labels)\n",
    "\n",
    "    lime_explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "    for i in range(0, len(examples), batch_size):\n",
    "        batch = examples[i:i+batch_size]\n",
    "        texts = []\n",
    "        for ex in batch:\n",
    "            enc = clf_tokenizer(\n",
    "                ex[\"text\"],\n",
    "                truncation=True,\n",
    "                padding=False,\n",
    "                max_length=max_len,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            truncated_text = clf_tokenizer.decode(enc[\"input_ids\"][0], skip_special_tokens=True)\n",
    "            texts.append(truncated_text)\n",
    "\n",
    "        \n",
    "        # SHAP counterfactuals ####################################\n",
    "        \n",
    "        shap_values = shap_explainer(texts, max_evals=shap_max_evals)\n",
    "\n",
    "        for j, text in enumerate(texts):\n",
    "            pred_label = np.argmax(predict_proba([text])[0])\n",
    "            \n",
    "            vals = shap_values.values[j]\n",
    "            tokens = shap_values.data[j]\n",
    "\n",
    "            # handle multi-class output\n",
    "            if vals.ndim == 1:\n",
    "                token_importances = vals\n",
    "            else:\n",
    "                token_importances = vals[:, pred_label]\n",
    "\n",
    "            top_indices = np.argsort(np.abs(token_importances))[-5:]\n",
    "            influential_tokens_shap = [tokens[idx].strip() for idx in top_indices if len(tokens[idx].strip()) > 0]\n",
    "\n",
    "            #print(\"influential_tokens_shap\",influential_tokens_shap)\n",
    "            for target_word in influential_tokens_shap:\n",
    "                #convert to MLM-compatible subword\n",
    "                subword = mlm_tokenizer.tokenize(target_word)\n",
    "                # print(\"subword\", subword)\n",
    "                if len(subword) == 0:\n",
    "                    continue\n",
    "                subword = subword[0]\n",
    "                candidates = generate_candidates(text, subword)\n",
    "                \n",
    "                for cand in candidates:\n",
    "                    new_text = text.replace(target_word, cand)\n",
    "                    new_pred = np.argmax(predict_proba([new_text])[0])\n",
    "                    if new_pred != pred_label:\n",
    "                        sim = semantic_similarity(text, new_text)\n",
    "                        flu = perplexity(new_text)\n",
    "                        cf_shap = {\n",
    "                            \"original_text\": text,\n",
    "                            \"original_pred\": pred_label,\n",
    "                            \"counterfactual_text\": new_text,\n",
    "                            \"counterfactual_pred\": new_pred,\n",
    "                            \"changed_word\": (target_word, cand),\n",
    "                            \"semantic_similarity\": sim,\n",
    "                            \"perplexity\": flu\n",
    "                        }\n",
    "                        metrics = evaluate_counterfactual(cf_shap, text, method=\"SHAP\")\n",
    "                        results.append(metrics)\n",
    "        pd.DataFrame(results).to_csv(cache_dir+f\"/intermediate_counterfactuals_{i}_shap.csv\", index=False)\n",
    "\n",
    "        # LIME counterfactuals ####################################\n",
    "  \n",
    "        for text in texts:\n",
    "            \n",
    "            exp = lime_explainer.explain_instance(\n",
    "                text,\n",
    "                predict_proba,\n",
    "                num_features=5,\n",
    "                labels=[0, 1],\n",
    "                num_samples=lime_num_samples\n",
    "            )\n",
    "\n",
    "            pred_label = np.argmax(predict_proba([text])[0])\n",
    "            influential_tokens = [w for w, score in sorted(exp.as_list(label=pred_label), key=lambda x: abs(x[1]), reverse=True)][:5]\n",
    "            if not influential_tokens:\n",
    "                continue\n",
    "\n",
    "            #print(\"influential_tokens_lime\",influential_tokens)\n",
    "            for target_word in influential_tokens:\n",
    "                subword = mlm_tokenizer.tokenize(target_word)\n",
    "                # print(\"subword\", subword)\n",
    "                if len(subword) == 0:\n",
    "                    continue\n",
    "                subword = subword[0]\n",
    "                candidates = generate_candidates(text, subword)\n",
    "\n",
    "                for cand in candidates:\n",
    "                    new_text = text.replace(target_word, cand)\n",
    "                    new_pred = np.argmax(predict_proba([new_text])[0])\n",
    "                    if new_pred != pred_label:\n",
    "                        sim = semantic_similarity(text, new_text)\n",
    "                        flu = perplexity(new_text)\n",
    "                        cf_lime = {\n",
    "                            \"original_text\": text,\n",
    "                            \"original_pred\": pred_label,\n",
    "                            \"counterfactual_text\": new_text,\n",
    "                            \"counterfactual_pred\": new_pred,\n",
    "                            \"changed_word\": (target_word, cand),\n",
    "                            \"semantic_similarity\": sim,\n",
    "                            \"perplexity\": flu\n",
    "                        }\n",
    "                        metrics = evaluate_counterfactual(cf_lime, text, method=\"LIME\")\n",
    "                        results.append(metrics)\n",
    "\n",
    "        pd.DataFrame(results).to_csv(cache_dir+f\"/intermediate_counterfactuals_{i}_shap_lime.csv\", index=False)\n",
    "        print(f\"Processed {min(i + batch_size, sample_size)}/{sample_size} examples\")\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"all_counterfactuals.csv\", index=False)\n",
    "\n",
    "    summary = df[df[\"success\"] == 1].groupby(\"method\").mean(numeric_only=True).to_dict()\n",
    "\n",
    "    return df, summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a52dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0be1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, summary = batch_evaluate(sample_size=-1, dataset_name=dataset_name)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcae19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c5ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b14914",
   "metadata": {},
   "source": [
    "nohup python counterfactual_gen.py > counter_gen_log.txt &\n",
    "\n",
    "nohup python counterfactual_gen.py > counter_gen_log2.txt &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e667c",
   "metadata": {},
   "source": [
    "\n",
    "cp /ssd_scratch/sweta.jena/intermediate_counterfactuals_14080_shap_lime.csv ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c396a03",
   "metadata": {},
   "source": [
    "nohup python counterfactual_gen_v2.py > counter_gen_log_v2.txt &\n",
    "\n",
    "nohup python counterfactual_gen_v2.py > counter_gen_log_v2_2.txt &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
